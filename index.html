<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Title</title>

  <link rel="stylesheet" type="text/css" href="main.css"/>

  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,600,700" rel="stylesheet">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Exo:ital,wght@0,300;0,400;0,600;0,800;0,900;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">

  <style>
    body {
      font-family: 'Exo', sans-serif;
    }
    h1{
      font-weight: bold;
      font-style: italic;
    }
    h2 {
      font-weight: bold;
    }
    h3 {
      font-weight: 500;
      font-style: italic;
    }

  </style>

</head>
<body>

<nav class="navbar navbar-default" style="background-color: #25f4ee">
	<div class="container-fluid">
		<div class="navbar-header">
			<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bsr-navbar-example" aria-expanded="false">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
			<a class="navbar-brand" href="#" style="color: #000000">TikTok, Race & Algorithms</a>
		</div>
		</div>
</nav>


<div class="container-fluid">
  <div id="conclusion-wrapper">
    <div id="conclusion">
      <img class='images img img-responsive' src="imgs/tiktoklogo.png" alt='blue and red tiktok logo on white background' id = "logo">
      <h1 style='color:#FFFFFF'>Race & Algorithms</h1>
      <h3 style='color:#FFFFFF'><i>Case Study: Race & Technologies of Surveillance</i></h3>
      <p style='color:#FFFFFF'><i>Kaitlyn Barbour, Spring 2022</i></p>

    </div>
  </div>

<div class="bodycontent">

<br>

<div id="toc_container">
    <ul class="toc_list">
      <li><a href="#section1">Background & Goals</a></li>
      <li><a href="#section2">The Algorithm</a>
        <ul>
          <li><a href="#profitability-section">Profitability</a></li>
          <li><a href="#privacy-section">Training, Web Scraping, & Privacy</a></li>
          <li><a href="#algorithms-section">Popularity & Algorithms of Oppression</a></li>
        </ul>
      </li>
      <li><a href="#section3">TikTok, Race, & Visibility</a>
        <ul>
          <li><a href="#opportunities-section">Creators & Unequal Opportunities</a></li>
          <li><a href="#jalaiah-section">Jalaiah Harmon & Renegade</a></li>
          <li><a href="#blm-section">Black Lives Matter & Community Guidelines</a></li>
        </ul>
      </li>
      <li><a href="#section4">Responses to the System</a>
        <ul>
          <li><a href="#algospeak-section">“Algospeak”</a></li>
          <li><a href="#boycotts-section">Black Creators & TikTok Boycotts</a></li>
        </ul>
      </li>
      <li><a href="#section5">Conclusion</a></li>
    </ul>
</div>

	<hr>
</div>

<div class="bodycontent" id="section1">

  <h2 class="pinkheaders">Background & Goals </h1>

    <p>Compared to other media giants (such as Facebook, Instagram, or Twitter), TikTok is relatively new. Thus, there isn’t a ton of scholarly research about TikTok, the ways that it is used, or the issues that it presents. TikTok can clearly be a valuable platform for sharing information, education, & entertainment.</p>
    <p>However — like most social media sites — there are a lot of problems that present themselves regarding the app and its usage. This prompted me to dig into those issues, particularly those regarding race, algorithms, and surveillance that appear on TikTok.</p>
    <p>This is by no means intended to be a comprehensive guide to the perils of TikTok, nor is it supposed to be an indictment of the platform. It is merely intended to highlight some of the issues with TikTok regarding race and surveillance technology, as well as highlighting places on which people could or should further investigate.</p>

</div>

<div class="bodycontent" id="section2">
  <h2 class="pinkheaders">The Algorithm</h2>

    <p>TikTok — like most social media companies — doesn’t allow for public review of its algorithm. However, it has publicly shared the broad outlines of its recommendation system, saying it takes into account factors including likes and comments as well as video information like captions, sounds and hashtags.</p>
    <p>This system means that watch time is key. The algorithm tries to get people addicted rather than giving them what they really want.”</p>
    <p>It also has been said to use a type of algorithm process called <b>“collaborative filtering.”</b> This system is based off of the idea that you will like similar content to people who share your interests, and creates "personalized" recommendations by showing you what other users who like the same things as you also like.</p>

<h3 id="profitability-section">Profitability</h3>

  <p> A 2021 New York Times article describes an internal company document produced by TikTok’s engineering team in Beijing. This document, called “TikTok Algo 101” lists four main goals for TikTok’s algorithm: <b>“user value,” “long-term user value,” “creator value,” and “platform value.”</b></p>

  <img class='center-block images img img-responsive' src="imgs/profitability.png" alt='Map relations of TikTok Algorithm'>

  <blockquote class=''>
    <p>Although TikTok seems to uncover things about users that they didn’t necessarily know about themselves, in reality it’s more accurate to say that TikTok shows you where your attention already goes—or would go, if you were freed from the social norms that keep your curiosity corralled offline.... <b>in case it wasn’t clear, TikTok’s real motivation isn’t psychoanalysis, it’s profit. The algorithm “is trying to differentiate you from … the vanilla user” to keep your attention (and keep earning money).</b></p>

    <footer>Johannes Eichstaedt, from  <cite title="Wired"><a href='https://www.wired.com/story/tiktok-algorithm-mental-health-psychology/' target='_blank'>Wired</a></cite></footer>
  </blockquote>

<h3 id="privacy-section">Training, Web Scraping, & Privacy</h3>
  <p>TikTok has a shaky history of respecting users’ privacy. </p>

  <blockquote class=''>
    <p>February 25, 2021 — "TikTok’s Chinese parent company ByteDance has agreed to pay $92 million in a settlement to U.S. users who are part of a class-action lawsuit alleging that the video-sharing app failed to get their consent to collect data in violation of a strict Illinois privacy law. The federal lawsuit alleged that TikTok broke the Illinois biometric privacy law, which allows suits against companies that harvest consumer data without consent, including via facial and fingerprint scanning."</p>
    <footer><cite title='Associated Press News'><a href='https://apnews.com/article/technology-lawsuits-biometrics-illinois-00be8815636b8f69d2742637bc1c4f1f/' target='_blank'>AP News</a></cite></footer>
  </blockquote>

  <p>Beyond violating legal restrictions on collecting user data, TikTok’s parent company ByteDance has also used user data in order to train their algorithm without users’ knowledge or consent. </p>

  <p>In 2017, ByteDance scraped short-form videos, usernames, profile pictures, and profile descriptions from Instagram, Snapchat, and other sources and then uploaded them to one of TikTok’s predecessors called Flipagram (<a href="https://www.buzzfeednews.com/article/emilybakerwhite/bytedance-scraped-fake-accounts-instagram-snapchat" target="_blank">BuzzFeed News</a>). Former employees say that the content was used to train the “For You” algorithm on US-based content <b>“so that it would better reflect the preferences of US users.”</b></p>

  <p>A former employee described this sort of growth tactic and the willingness to scrape user data without consent in pursuit of creating a more addictive algorithm as a symptom of <b>a larger, industry-wide obsession with growth at any cost:</b> “The US public and US media often attribute unethical growth strategies practiced by Chinese tech companies to ‘Chinese tech culture,’ when very often those tactics are directly copied from FAANG (Facebook, Amazon, Apple, Netflix, and Google) companies.”</p>

<h3 id="algorithms-section">Popularity & Algorithms of Oppression</h3>
  <p>Another concerning component of TikTok’s algorithm is how it recommends accounts to users, as well as TikTok’s response. Back in February 2020, Marc Faddoul a research scientist at the University of California Berkeley observed that the profiles recommended by TikTok when he followed a new account seemed very physically similar to the profile photo of the original account: “Following black men led to recommendations to follow more black men. Following white men with beards produced recommendations for more white men with beards. Following elderly people spawned recommendations for other elderly people. And on and on.” (<a href="https://www.vox.com/recode/2020/2/25/21152585/tiktok-recommendations-profile-look-alike" target="_blank">Vox</a>)</p>

  <p>Some have been able to replicate his results, while others have noted that the recommendations they saw shared an interest instead of appearances. However, it <b>raises the question of how the algorithm is trained and what factors go into recommendations on social media platforms such as TikTok.</b> Why would following someone with certain demographic traits lead to recommendations for users that look similar to them and how can these recommendations lead to selective information environments?</p>

  <p>When asked about this, TikTok responded, saying that “Our recommendation of accounts to follow is based on user behavior: users who follow account A also follow account B, so if you follow A you are likely to also want to follow B.”</b>

  <p>TikTok’s response blames recommendation results on users instead of their algorithm. Yet, it is TikTok’s algorithm that is designed to keep users engaged and following new users by recommending content that will match their interests and keep them scrolling in order to maximize profit. </p>

  <blockquote class=''>
    <p>The dominant notion of search results as being both “objective” and “popular” makes it seem as if misogynist or racist search results are a simple mirror of the collective. Not only do problematic search results seem “normal,” but they seem completely unavoidable as well, even though these ideas have been thoroughly debunked by scholars. </p>
    <footer>Safiya Umoja Noble, from <cite title='Algorithms of Oppression'><a href='https://nyupress.org/9781479837243/algorithms-of-oppression/' target='_blank'>Algorithms of Oppression</a></cite></footer>
  </blockquote>

  <p>By blaming biased search or recommendation results on the algorithm, <b>TikTok is upholding the false idea that technology is neutral and objective,</b> instead of something that can be <b>leveraged by companies in pursuit of goals such as profit or upholding structures of power</b>.</p>

</div>
<br>
<br>

<div id="conclusion-wrapper">
  <div id="conclusion">
    <p style='color:#FFFFFF' id = "question-wrapper">
      How does TikTok’s desire for maximizing profit and growth manifest itself in the algorithm?
      <br><br>What choices are made in the name of growth and profitability?
      <br><br>How do these choices manifest themselves?
      <br><br>How do those choices uphold structures of power and oppression on the platform and beyond?
    </p>
  </div>
</div>

<div class="bodycontent">
<br>

<h2 class="pinkheaders" id="section3" >TikTok, Race & Visibility</h2>
<h3 id="opportunities-section">Creators & Unequal Opportunities</h3>

  <p>One key way in which racial disparities appear on TikTok is the opportunities that creators gain. Many Black creators of some of the most viral dance trends have not been given the same opportunities as their white TikTok counterparts. (<a href="https://www.insider.com/alors-on-danse-black-tiktokers-crediting-shadowbanning-race-2021-12?utm_source=npr_newsletter&utm_medium=email&utm_content=20220213&utm_term=6317695&utm_campaign=code-switch&utm_id=41290416&orgid=305&utm_att1=nprnews" target="_blank">Insider</a>).</p>

  <p>TikTok’s use of sounds helps dance trends spread like wildfire across the app. In order to find the original creator of a dance, users must search through the videos under a sound where sometimes the original video is marked as such. However, not all dances are marked as the original, and because TikTok’s sounds do not have any sort or filter function, finding the first post with a dance under a popular sound can be incredibly difficult. TikTok does not have any requirement to credit a dance’s creator nor any automated way to make this happen.  Only within the past year did TikTok even enable the option to tag users in a video; previously any credits had to take up space within the limited characters of a caption or in a comment.</p>

  <p>But, missing out on credit isn’t just about losing recognition for one’s work: <b>“To be robbed of credit on TikTok is to be robbed of real opportunities. In 2020, virality means income:</b> Creators of popular dances… often amass large online followings and become influencers themselves. That, in turn, opens the door to brand deals, media opportunities… etc.” (<a href="https://www.nytimes.com/2020/02/13/style/the-original-renegade.html" target="_blank">NYT</a>)</p>

  <img class='center-block images img img-responsive' src="imgs/Jalaiah.png" alt='Jalaiah Harmon on a street in Atlanta'>

  <h3 id="jalaiah-section">Jalaiah Harmon & Renegade</h3>
  <p>Perhaps the most notable example of the unequal racial opportunities distributed across the plaform is that of Jalaiah Harmon. </p>

  <p>Jalaiah Harmon is a Black teenager from Atlanta who was 14 at the time her dance “Renegade” went viral on TikTok. She created the dance in September 2019 on another app, before it was brought to TikTok in October by another user. Before long, an up-and-coming 15 year old white TikToker named Charli D’Amelio had posted a video of herself doing it, as did many other TikTok influencers.<b> None gave Jalaiah credit. </b></p>

  <p>Very few individuals even knew the original creator of the dance until months after it had blown up, when a February 2020 article from the New York Times explained the dance’s creator and gave her recognition. Since the article, Harmon has been the subject of her own docuseries, yet has nowhere near the recognition of other TikTokers who profited off of Harmon’s dance.</p>

  <p>Charli D’Amelio, who rose to fame partially as a result of her videos to Renegade, is still the most-followed TikToker in the world. D’Amelio now stars in a Hulu Reality show with her family. </p>

  <img class='center-block images img img-responsive' src="imgs/charli.png" alt='Promo for DAmelio family Hulu Show'>
  <br>

  <p>Another well-known example is that of Addison Rae, who has been a popular TikToker known for her dances since at least late 2019. </p>

  <p>In early 2021, Jimmy Fallon hosted Addison Rae on his show for a segment where she “performed” various TikTok dances. However, she was not the creator of any of the dances herself, and their creators — many of whom are Black — were absent and not credited on screen (though their handles were listed in the video description of the YouTube upload).</p>

  <p>This sparked a debate over TikTok, race, credit, and pop culture. Similar to the different treatment between Jalaiah Harmon and Charli D’Amelio, Addison Rae was given opportunities to profit off of the work of Black creators without acknowledging where those trends came from and who made them. </p>

  <p>Addison Rae is still TikTok’s third most followed creator, and made nearly $5 million in 2020 from TikTok alone, “getting views from videos she made recreating dances from black choreographers” (<a href="https://www.bbc.com/news/world-us-canada-57841055" target="_blank">BBC</a>). She recently starred in Netflix’s 2021 rom-com release “He’s All That” and has reportedly signed a multi-movie deal with Netflix (<a href="https://www.insider.com/jimmy-fallon-addison-rae-tiktok-dance-black-creators-2021-3" target="_blank">Insider</a>).</p>


  <img class='center-block images img img-responsive' src="imgs/addison.png" alt='Promo for DAmelio family Hulu Show'>


  <p>Now, TikTok would probably argue that these unequal results are a result of processes that are exterior to the app, that it’s not the app’s fault that D’Amelio and Rae got famous while Harmon went unnoticed. Yet, there are steps that could be taken to give Black creators the credit they deserve on the app, which could lead to more opportunities off the app.</p>

  <blockquote class=''>
    <p>The animating force of the New Jim Code is that tech designers encode judgments into technical systems but claim that the racist results of their designs are entirely exterior to the encoding process. </p>
    <footer>Ruja Benjamin, from <cite title='Race After Technology'><a href='https://www.ruhabenjamin.com/race-after-technology' target='_blank'>Race After Technology</a></cite></footer>
  </blockquote>

<h3 id="blm-section">Black Lives Matter & Community Guidelines</h3>

  <blockquote class=''>
    <p>Some technologies fail to see Blackness, while others render Black people hypervisible and expose them to systems of racial surveillance.</p>
    <footer>Ruja Benjamin, from <cite title='Race After Technology'><a href='https://www.ruhabenjamin.com/race-after-technology' target='_blank'>Race After Technology</a></cite></footer>
  </blockquote>

  <p>Black users have consistently had to fight for visibility on TikTok in terms of getting credit for creating trends. Yet beyond that, Black creators have had to fight against TikTok’s “Community Guidelines” themselves to share content.</p>

  <p>In the midst of many Black Lives Matter protests in June 2020, users who typed #BlackLivesMatter or #GeorgeFloyd into their video captions on the editing screen were told the hashtag had zero views (<a href="https://www.cnbc.com/2020/06/02/tiktok-blacklivesmatter-censorship.html" target="_blank">CNBC</a>). TikTok later apologized for the “technical glitch” that occurred to make it appear as if those hashtags had no views. TikTok stated that posts with these hashtags actually had over 2 billion views. </p>

  <p>There have also been several instances where creators found that terms such as “Black Lives Matter’’ and “Black people” were being suppressed by automated moderation (<a href="https://www.npr.org/sections/codeswitch/2022/02/14/1080577195/tiktok-algorithm" target="_blank">NPR</a>). One Black creator, Ziggi Tyler, found that typing phrases like “Black Lives Matter” or “Black Success” in his Marketplace creator bio would flag them as inappropriate content. However, “white supremacy” or “white success” did not trigger this same warning (<a href="https://www.vox.com/recode/2021/7/7/22566017/tiktok-black-creators-ziggi-tyler-debate-about-black-lives-matter-racial-bias-social-media?utm_source=npr_newsletter&utm_medium=email&utm_content=20220213&utm_term=6317695&utm_campaign=code-switch&utm_id=41290416&orgid=305&utm_att1=nprnews" target="_blank">Vox</a>). </p>

  <p>TikTok’s explanation was that the app was mistakenly flagging phrases like “Black Lives Matter" “because its hate speech detector is triggered by a combination of words involving the words “Black” and “audience” — because “audience” contains the word “die” in it. Yet, as Tyler says: <b>“Regardless of what the algorithm is and how it picked up, somebody had to program that algorithm… </b> And if [the problem] is the algorithm, and the marketplace has been available since [2020], why wasn’t this a conversation you had with your team, knowing there have been racial controversies?”</p>

  <blockquote class=''>
    <p>Computer systems are a part of the larger matrix of systemic racism. Just as legal codes are granted an allure of objectivity – “justice is (color)blind” goes the fiction – <b>there is enormous mystique around computer codes, which hides the human biases involved in technical design. </b>
    <footer>Ruja Benjamin, from <cite title='Race After Technology'><a href='https://www.ruhabenjamin.com/race-after-technology' target='_blank'>Race After Technology</a></cite></footer>
  </blockquote>

</div>
<br><br>

<div id="conclusion-wrapper">
  <div id="conclusion">
    <p style='color:#FFFFFF' id = "question-wrapper">
      How does TikTok’s desire for maximizing profit and growth manifest itself in the algorithm?
      <br><br>How does TikTok’s design lead to unequal opportunities for creators on and off the app?
      <br><br>How does visibility on the platform lead to surveillance?
      <br><br>What choices are obscured by language that blames human biases on the algorithm and computer code?
    </p>
  </div>
</div>

<div class="bodycontent">
<br>
<br>
<h2 class="pinkheaders" id="section4">Responses to the System</h2>
  <p>Knowing that there are problems regarding TikTok’s algorithm, race, and surveillance, how have individuals adapted to this media landscape? What methods of communication have been developed to adjust to content moderation algorithms? What tactics are used to push back against technology that oppresses? </p>

<h3 id="algospeak-section">“Algospeak”</h3>
  <p>TikTok’s <a href="https://www.tiktok.com/community-guidelines?lang=en#29" target="_blank">Community Guidelines</a> policies appear to be very similar to those of other social media sites: it does not allow content that contains violence and hateful behavior, harassment and bullying, adult nudity and sexual activities, graphic content, misleading or infringing content, and content that may be harmful to minors. However, TikTok relies very heavily on content moderation in order to keep the platform free of unwanted language or behavior. TikTok’s algorithm in particular is likely to flag videos that contain words that could be problematic for its community guidelines, regardless of context.</p>

  <p>One way that creators and users alike have adapted to content moderation technology is through the creation of “algospeak.” Algospeak refers to code words or turns of phrase users have adopted in an effort to create a brand-safe lexicon that will avoid getting their posts removed or down-ranked by content moderation systems (<a href="https://www.washingtonpost.com/technology/2022/04/08/algospeak-tiktok-le-dollar-bean/?utm_source=instagram&utm_medium=social&utm_campaign=wp_main&crl8_id=31b8775b-e87b-464b-b225-0bf97243f63b" target="_blank">Washington Post</a>).</p>

  <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Algorithms are causing human language to reroute around them in real time. I’m listening to this youtuber say things like “the bad guy unalived his minions” because words like “kill” are associated with demonetization</p>&mdash; badidea 🪐 (@0xabad1dea) <a href="https://twitter.com/0xabad1dea/status/1471054750531702785?ref_src=twsrc%5Etfw">December 15, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  <p>For example, mentions of suicide or self-harm could fall under the category of graphic content, educational content about sex, pregnancy, and menstrual cycles could be seen as promoting adult nudity or sexual activities. Others have found that discussions of racism and homophobia have been flagged or downranked, despite not explicitly violating any of the community guidelines policies. </p>

  <p>As a result, creators on TikTok have adopted various “algospeak” code words:</p>
  <ul>
    <li>“Dead” is no longer “Dead,” it’s now “Unalive.” </li>
    <li>Sex becomes “Seggs.” </li>
    <li>Sexual Assault becomes “SA.” </li>
    <li>Sex Workers are “Accountants.” </li>
    <li>The Pandemic is “The Panini” or the “Panda Express.” </li>
    <li>Lesbians are “Le Dolla Beans” (coming from the spelling Le$bian).</li>
    <li>LGBT is the “Alphabet Mafia.”</li>
    <li>Porn is 🌽.</li>
  </ul>

  <p>While algospeak is used as a way to try to get around content moderation systems — to sometimes comical effect — it points at a darker part of TikTok’s algorithm. Not only is TikTok not transparent about what it is trying to censor, users have to try their best to avoid censorship, TikTok then tries to filter those new code words, and the cycle continues in “a game of whack-a-mole.”</p>

  <blockquote class=''>
    <p>The reality is that tech companies have been using automated tools to moderate content for a really long time and while it’s touted as this sophisticated machine learning, it’s often just a list of words they think are problematic</p>

    <footer>Ángel Díaz, from <cite title='Washington Post'><a href='https://www.washingtonpost.com/technology/2022/04/08/algospeak-tiktok-le-dollar-bean/?utm_source=instagram&utm_medium=social&utm_campaign=wp_main&crl8_id=31b8775b-e87b-464b-b225-0bf97243f63b' target='_blank'>Washington Post</a></cite></footer>
  </blockquote>

<h3 id="boycotts-section">Black Creators & TikTok Boycotts</h3>

  <p>Beyond adapting to content moderation systems and manipulating language to avoid censorship, creators have taken a more active approach to dealing with oppressive systems, including boycotting TikTok and striking from creating content for the app. </p>

  <p>Most recently, in July 2021, Black creators on TikTok held a strike to draw attention to the lack of credit that they receive (<a href="https://www.washingtonpost.com/lifestyle/2021/06/25/black-tiktok-strike/" target="_blank">Washington Post</a>). In particular, Black TikTokers refused to choreograph to Rapper Megan Thee Stallion’s latest release at the time — “Thot Shit.” The strike led to many less videos being created at the time which highlighted the strike and brought attention to the issue.</p>

  <p>TikTok released a statement highlighting its commitment to diversity and inclusion, saying: “Over the past year, our teams have continued working to elevate and support Black voices and causes, while fostering an inclusive environment on our platform and within our workplace.” It also said that it was training staff "to better understand more nuanced content like culture appropriation and slurs" and endeavoured to give users "tools to empower our community," (<a href="https://www.bbc.com/news/world-us-canada-57841055" target="_blank">BBC</a>) but did not directly mention the strike itself.</p>

  <p>Yet, months after the strike, many of these same problems persist on the platform, and Black creators still struggle to recieve credit for their work.</p>
<br>
<br>
</div>


<div id="conclusion-wrapper">
  <div id="conclusion">
    <h2 id = "section5" style='color:#FFFFFF;' class='jumbotronic'>Conclusion</h2>
    <p style='color:#FFFFFF'>
      TikTok itself says it is working to rectify the issues with the platform, including increasing equity efforts, bringing in more Black advisors, acknowledging intersectional Black experiences on social media, meeting with Black creators and investing in Black creatives on the app.
      <br><br>All of these efforts represent important steps in creating a more equitable experience on the app. However, it bears asking if these steps will be enough when the algorithm is intended to hook audiences at whatever cost in order to maximize profit. Such language continues to place the blame for racist results on things that are exterior to technology or technical glitches and continue the false perception that technology itself is neutral and objective when it is far from it.
      <br><br>
      <blockquote class=''>
        <p style='color:#FFFFFF'>The more our lives become intertwined and caught up in tech and social media algorithms, the more it’s worth trying to understand and unpack just how those algorithms work. Who becomes viral, and why? Who gets harassed, who gets defended, and what are the lasting repercussions? And how does the internet both obscure and exacerbate the racial and gender dynamics that already animate so much of our social interactions?</p>
        <footer style='color:#FFFFFF'>Jess Kung, from <cite title='NPR'><a href='https://www.npr.org/sections/codeswitch/2022/02/14/1080577195/tiktok-algorithm' target='_blank' style='color:#FFFFFF'>NPR</a></cite></footer>
      </blockquote>
    </p>
  </div>
</div>
